{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning to learn\n",
    "\n",
    "We explore the bandit problem by representing it as an imperfect information game and solving it with a counterfactual regret minimization algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zerosum as zs\n",
    "\n",
    "from typing import cast\n",
    "from dataclasses import dataclass, replace\n",
    "from itertools import islice, chain\n",
    "import random"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The bandit game\n",
    "\n",
    "The bandit player chooses from a set of arms at each round, and receives a reward from the arm chosen. The reward is drawn from a distribution that depends on the arm chosen. The player's goal is to maximize their reward. The number of rounds is fixed before-hand.\n",
    "\n",
    "Our framework can currently only handle zero-sum two player games. We therefore study an alternative problem where two players play the game simultaneously. They do not share information. The payoff of each player is adjusted by the payoff of their opponent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(slots=True, frozen=True)\n",
    "class Init:\n",
    "    means: tuple[float, ...]\n",
    "\n",
    "\n",
    "@dataclass(slots=True, frozen=True)\n",
    "class Choice:\n",
    "    arm: int\n",
    "\n",
    "\n",
    "@dataclass(slots=True, frozen=True)\n",
    "class Reward:\n",
    "    reward: float\n",
    "\n",
    "\n",
    "Action = Init | Reward | Choice\n",
    "\n",
    "\n",
    "@dataclass(slots=True, frozen=True)\n",
    "class InfoSet:\n",
    "    round: int\n",
    "    arms: int\n",
    "    history: tuple[Action, ...]\n",
    "\n",
    "    def actions(self):\n",
    "        return tuple(Choice(i) for i in range(self.arms))\n",
    "\n",
    "\n",
    "@dataclass(slots=True, frozen=True)\n",
    "class Learn:\n",
    "    rounds: int\n",
    "    arms: int\n",
    "\n",
    "    round: int = 0\n",
    "    history: tuple[Action, ...] = ()\n",
    "\n",
    "    @property\n",
    "    def means(self):\n",
    "        return cast(Init, self.history[0]).means\n",
    "\n",
    "    @property\n",
    "    def terminal(self):\n",
    "        return self.round >= self.rounds\n",
    "\n",
    "    def payoff(self, player: zs.Player):\n",
    "        s0 = islice(self.history, 2, None, 4)\n",
    "        s1 = islice(self.history, 4, None, 4)\n",
    "\n",
    "        score = 0\n",
    "        for a0, a1 in zip(s0, s1):\n",
    "            a0 = cast(Reward, a0)\n",
    "            a1 = cast(Reward, a1)\n",
    "            score += a0.reward - a1.reward\n",
    "\n",
    "        return score if player == 0 else -score\n",
    "\n",
    "    @property\n",
    "    def chance(self):\n",
    "        return len(self.history) % 2 == 0\n",
    "\n",
    "    def chances(self):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def _init(self):\n",
    "        means = tuple(random.random() for _ in range(self.arms))\n",
    "        return Init(means)\n",
    "    \n",
    "    # overriding this method in a subclass is an easy method to create\n",
    "    # a bandit game with different reward distributions\n",
    "\n",
    "    def sample(self) -> Action:\n",
    "        if len(self.history) == 0:\n",
    "            return self._init()\n",
    "\n",
    "        *_, action = self.history\n",
    "        action = cast(Choice, action)\n",
    "        if random.random() > self.means[action.arm]:\n",
    "            return Reward(1)\n",
    "        return Reward(0)\n",
    "\n",
    "    @property\n",
    "    def active(self) -> zs.Player:\n",
    "        if len(self.history) % 4 == 1:\n",
    "            return zs.Player(0)\n",
    "        return zs.Player(1)\n",
    "\n",
    "    def infoset(self, player: zs.Player):\n",
    "        choices, rewards = self.history[1::4], self.history[2::4]\n",
    "        if player == 1:\n",
    "            choices, rewards = self.history[3::4], self.history[4::4]\n",
    "\n",
    "        history = tuple(chain.from_iterable(zip(choices, rewards)))\n",
    "        return InfoSet(self.round, self.arms, history)\n",
    "\n",
    "    def apply(self, action: Action):\n",
    "        round = self.round\n",
    "        if len(self.history) > 1 and len(self.history) % 4 == 0:\n",
    "            round += 1\n",
    "\n",
    "        return replace(self, round=round, history=self.history + (action,))\n",
    "\n",
    "\n",
    "_: zs.Game[Action, InfoSet] = Learn(0, 3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can immediately attempt to find a Nash equilibrium for this game, but we will find the number of infosets is quite large compared to the essential complexity of the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def game():\n",
    "    return Learn(3, 2)\n",
    "\n",
    "\n",
    "impl = zs.ESLCFR(1000)\n",
    "algo = zs.Algorithm(impl, game)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 1182.46it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "for _ in tqdm(range(100)):\n",
    "    algo.once()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(impl.strategies)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can construct an abstraction of the game by capturing only the essential information. The player how many times each arm was pulled and their average payoff. The latter value is bucketed. The player also knows which round they are playing (it is implicit in the last information)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(slots=True, frozen=True)\n",
    "class Scores:\n",
    "    scores: tuple[int, ...]\n",
    "\n",
    "\n",
    "def aggregate(buckets: int):\n",
    "    @zs.algebraic\n",
    "    def aggregate(infoset: zs.InfoSet):\n",
    "        infoset = cast(InfoSet, infoset)\n",
    "        means = [0.0] * infoset.arms\n",
    "        ns = [0] * infoset.arms\n",
    "\n",
    "        for choice, action in zip(infoset.history[::2], infoset.history[1::2]):\n",
    "            arm = cast(Choice, choice).arm\n",
    "            reward = cast(Reward, action).reward\n",
    "\n",
    "            means[arm] = (reward + means[arm] * ns[arm]) / (ns[arm] + 1)\n",
    "            ns[arm] += 1\n",
    "        \n",
    "        return Scores(tuple(round(m * buckets) for m in means))\n",
    "    return aggregate\n",
    "\n",
    "\n",
    "@dataclass(slots=True, frozen=True)\n",
    "class Chosen:\n",
    "    arms: tuple[int, ...]\n",
    "\n",
    "\n",
    "@zs.algebraic\n",
    "def chosen(infoset: zs.InfoSet):\n",
    "    infoset = cast(InfoSet, infoset)\n",
    "\n",
    "    arms = [0] * infoset.arms\n",
    "    for choice in infoset.history[::2]:\n",
    "        arm = cast(Choice, choice).arm\n",
    "        arms[arm] += 1\n",
    "\n",
    "    return Chosen(tuple(arms))\n",
    "\n",
    "def actions(infoset: zs.InfoSet):\n",
    "    return infoset.actions()\n",
    "\n",
    "\n",
    "def abstract(buckets: int):\n",
    "    @zs.abstract(Learn, aggregate(buckets) * chosen, actions)\n",
    "    class Abstraction(Learn):\n",
    "        ...\n",
    "\n",
    "    return Abstraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstraction = cast(type[Learn], abstract(3))\n",
    "\n",
    "def game(rounds: int = 3, arms: int = 2):\n",
    "    return abstraction(rounds, arms)\n",
    "\n",
    "\n",
    "impl = zs.ESLCFR(100)\n",
    "algo = zs.Algorithm(impl, game)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:02<00:00, 383.14it/s]\n"
     ]
    }
   ],
   "source": [
    "for _ in tqdm(range(1000)):\n",
    "    algo.once()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice there are significantly fewer information sets !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(impl.strategies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(Scores(scores=(0, 0)), Chosen(arms=(0, 0))): {Choice(arm=0): 0.26755051901177024,\n",
       "  Choice(arm=1): 0.7324494809882297},\n",
       " (Scores(scores=(3, 0)), Chosen(arms=(1, 0))): {Choice(arm=0): 0.9970548772799908,\n",
       "  Choice(arm=1): 0.0029451227200092958},\n",
       " (Scores(scores=(2, 0)), Chosen(arms=(2, 0))): {Choice(arm=0): 0.9629846061592933,\n",
       "  Choice(arm=1): 0.037015393840706706},\n",
       " (Scores(scores=(3, 3)), Chosen(arms=(1, 1))): {Choice(arm=0): 0.0,\n",
       "  Choice(arm=1): 1.0},\n",
       " (Scores(scores=(0, 3)), Chosen(arms=(0, 1))): {Choice(arm=0): 1.0723992855722124e-05,\n",
       "  Choice(arm=1): 0.9999892760071443},\n",
       " (Scores(scores=(0, 3)), Chosen(arms=(1, 1))): {Choice(arm=0): 2.438489112146117e-06,\n",
       "  Choice(arm=1): 0.9999975615108878},\n",
       " (Scores(scores=(0, 3)), Chosen(arms=(0, 2))): {Choice(arm=0): 0.0,\n",
       "  Choice(arm=1): 1.0},\n",
       " (Scores(scores=(0, 0)), Chosen(arms=(0, 1))): {Choice(arm=0): 0.9976564698865356,\n",
       "  Choice(arm=1): 0.0023435301134643927},\n",
       " (Scores(scores=(0, 0)), Chosen(arms=(0, 2))): {Choice(arm=0): 0.9994929006085193,\n",
       "  Choice(arm=1): 0.0005070993914807308},\n",
       " (Scores(scores=(3, 0)), Chosen(arms=(2, 0))): {Choice(arm=0): 1.0,\n",
       "  Choice(arm=1): 0.0},\n",
       " (Scores(scores=(3, 0)), Chosen(arms=(1, 1))): {Choice(arm=0): 0.9999818666316664,\n",
       "  Choice(arm=1): 1.8133368333612557e-05},\n",
       " (Scores(scores=(0, 2)), Chosen(arms=(0, 2))): {Choice(arm=0): 0.6272256496378319,\n",
       "  Choice(arm=1): 0.37277435036216805},\n",
       " (Scores(scores=(0, 0)), Chosen(arms=(1, 0))): {Choice(arm=0): 0.003871613705349238,\n",
       "  Choice(arm=1): 0.9961283862946507},\n",
       " (Scores(scores=(0, 0)), Chosen(arms=(2, 0))): {Choice(arm=0): 0.6071544656186524,\n",
       "  Choice(arm=1): 0.3928455343813475},\n",
       " (Scores(scores=(0, 0)), Chosen(arms=(1, 1))): {Choice(arm=0): 0.1358242524627203,\n",
       "  Choice(arm=1): 0.8641757475372797}}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zs.normalize(impl.strategies)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clean",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7ac02b84f0b2c07ad9d596dfc0dd5b68046a23d9882df65ad98f7b44c27b887b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
