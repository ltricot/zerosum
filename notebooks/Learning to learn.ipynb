{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning to learn\n",
    "\n",
    "We explore the bandit problem by representing it as an imperfect information game and solving it with a counterfactual regret minimization algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zerosum as zs\n",
    "\n",
    "from typing import cast\n",
    "from dataclasses import dataclass, replace\n",
    "from itertools import islice, chain\n",
    "import random"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The bandit game\n",
    "\n",
    "The bandit player chooses from a set of arms at each round, and receives a reward from the arm chosen. The reward is drawn from a distribution that depends on the arm chosen. The player's goal is to maximize their reward. The number of rounds is fixed before-hand.\n",
    "\n",
    "Our framework can currently only handle zero-sum two player games. We therefore study an alternative problem where two players play the game simultaneously. They do not share information. The payoff of each player is adjusted by the payoff of their opponent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(slots=True, frozen=True)\n",
    "class Init:\n",
    "    means: tuple[float, ...]\n",
    "\n",
    "\n",
    "@dataclass(slots=True, frozen=True)\n",
    "class Choice:\n",
    "    arm: int\n",
    "\n",
    "\n",
    "@dataclass(slots=True, frozen=True)\n",
    "class Reward:\n",
    "    reward: float\n",
    "\n",
    "\n",
    "Action = Init | Reward | Choice\n",
    "\n",
    "\n",
    "@dataclass(slots=True, frozen=True)\n",
    "class InfoSet:\n",
    "    player: zs.Player\n",
    "    round: int\n",
    "    rounds: int\n",
    "    arms: int\n",
    "    history: tuple[Action, ...]\n",
    "\n",
    "    def actions(self):\n",
    "        return tuple(Choice(i) for i in range(self.arms))\n",
    "\n",
    "\n",
    "@dataclass(slots=True, frozen=True)\n",
    "class Learn:\n",
    "    rounds: int\n",
    "    arms: int\n",
    "\n",
    "    round: int = 0\n",
    "    history: tuple[Action, ...] = ()\n",
    "\n",
    "    @property\n",
    "    def means(self):\n",
    "        return cast(Init, self.history[0]).means\n",
    "\n",
    "    @property\n",
    "    def terminal(self):\n",
    "        return self.round >= self.rounds\n",
    "\n",
    "    def payoff(self, player: zs.Player):\n",
    "        s0 = islice(self.history, 2, None, 4)\n",
    "        s1 = islice(self.history, 4, None, 4)\n",
    "\n",
    "        sco = 0\n",
    "        for a0, a1 in zip(s0, s1):\n",
    "            a0 = cast(Reward, a0)\n",
    "            a1 = cast(Reward, a1)\n",
    "            sco += a0.reward - a1.reward\n",
    "        \n",
    "        return sco if player == 0 else -sco\n",
    "\n",
    "    @property\n",
    "    def chance(self):\n",
    "        return len(self.history) % 2 == 0\n",
    "\n",
    "    def chances(self):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def _init(self):\n",
    "        means = tuple(random.random() for _ in range(self.arms))\n",
    "        return Init(means)\n",
    "    \n",
    "    # overriding this method in a subclass is an easy method to create\n",
    "    # a bandit game with different reward distributions\n",
    "\n",
    "    def sample(self) -> Action:\n",
    "        if len(self.history) == 0:\n",
    "            return self._init()\n",
    "\n",
    "        *_, action = self.history\n",
    "        action = cast(Choice, action)\n",
    "\n",
    "        if random.random() < self.means[action.arm]:\n",
    "            return Reward(1)\n",
    "\n",
    "        return Reward(0)\n",
    "\n",
    "    @property\n",
    "    def active(self) -> zs.Player:\n",
    "        if (len(self.history) - 1) % 4 == 0:\n",
    "            return zs.Player(0)\n",
    "        return zs.Player(1)\n",
    "\n",
    "    def infoset(self, player: zs.Player):\n",
    "        choices, rewards = self.history[1::4], self.history[2::4]\n",
    "        if player == 1:\n",
    "            choices, rewards = self.history[3::4], self.history[4::4]\n",
    "\n",
    "        history = tuple(chain.from_iterable(zip(choices, rewards)))\n",
    "        return InfoSet(player, self.round, self.rounds, self.arms, history)\n",
    "\n",
    "    def apply(self, action: Action):\n",
    "        round = self.round\n",
    "        if len(self.history) > 1 and len(self.history) % 4 == 0:\n",
    "            round += 1\n",
    "\n",
    "        return replace(self, round=round, history=self.history + (action,))\n",
    "\n",
    "\n",
    "_: zs.Game[Action, InfoSet] = Learn(0, 3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can immediately attempt to find a Nash equilibrium for this game, but we will find the number of infosets is quite large compared to the essential complexity of the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def game():\n",
    "    return Learn(5, 2)\n",
    "\n",
    "\n",
    "impl = zs.ESCFR()\n",
    "algo = zs.Algorithm(impl, game)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Learn(rounds=5, arms=2, round=1, history=(Init(means=(0.30513534175980606, 0.8990895618169512)), Choice(arm=0), Reward(reward=1), Choice(arm=0), Reward(reward=1)))"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = game()\n",
    "\n",
    "g = g.apply(g.sample())\n",
    "g = g.apply(Choice(0))\n",
    "g = g.apply(g.sample())\n",
    "g = g.apply(Choice(0))\n",
    "g = g.apply(g.sample())\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:02<00:00, 231.70it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "for _ in tqdm(range(500)):\n",
    "    algo.once()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "682"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(impl.strategies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(n, game, strategies):\n",
    "    payoff = 0\n",
    "    for _ in tqdm(range(n)):\n",
    "        g = game()\n",
    "\n",
    "        bef = False\n",
    "        while not g.terminal:\n",
    "            if g.chance:\n",
    "                action = g.sample()\n",
    "                if bef and isinstance(action, Reward):\n",
    "                    payoff += action.reward\n",
    "                    bef = False\n",
    "\n",
    "                g = g.apply(action)\n",
    "                continue\n",
    "\n",
    "            infoset = g.infoset(g.active)\n",
    "\n",
    "            action = infoset.actions()[0]\n",
    "            if infoset in impl.strategies:\n",
    "                s = impl.strategies[infoset]\n",
    "\n",
    "                try:\n",
    "                    # action, = random.choices(tuple(s), weights=tuple(s.values()))\n",
    "                    action = max(s, key=s.get)\n",
    "                except ValueError:\n",
    "                    action = random.choice(infoset.actions())\n",
    "\n",
    "            bef = (g.active == 0)\n",
    "            g = g.apply(action)\n",
    "\n",
    "    return payoff / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subg():\n",
    "    return game().apply(Init((0.2, 0.8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 6579.60it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.932"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(1000, subg, impl.strategies)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can construct an abstraction of the game by capturing only the essential information. The player how many times each arm was pulled and their average payoff. The latter value is bucketed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(slots=True, frozen=True)\n",
    "class Player:\n",
    "    _: int\n",
    "\n",
    "\n",
    "@zs.algebraic\n",
    "def player(infoset: zs.InfoSet):\n",
    "    infoset = cast(InfoSet, infoset)\n",
    "    return Player(infoset.player)\n",
    "\n",
    "\n",
    "@dataclass(slots=True, frozen=True)\n",
    "class Round:\n",
    "    _: int\n",
    "\n",
    "\n",
    "@zs.algebraic\n",
    "def whichround(infoset: zs.InfoSet):\n",
    "    infoset = cast(InfoSet, infoset)\n",
    "    return Round(infoset.round)\n",
    "\n",
    "\n",
    "@dataclass(slots=True, frozen=True)\n",
    "class Scores:\n",
    "    scores: tuple[int, ...]\n",
    "\n",
    "\n",
    "@zs.algebraic\n",
    "def aggregate(infoset: zs.InfoSet):\n",
    "    infoset = cast(InfoSet, infoset)\n",
    "    ns = [0] * infoset.arms\n",
    "\n",
    "    for choice, action in zip(infoset.history[::2], infoset.history[1::2]):\n",
    "        arm = cast(Choice, choice).arm\n",
    "        reward = cast(Reward, action).reward\n",
    "        ns[arm] += int(reward)\n",
    "    \n",
    "    return Scores(tuple(ns))\n",
    "\n",
    "\n",
    "@dataclass(slots=True, frozen=True)\n",
    "class Chosen:\n",
    "    arms: tuple[int, ...]\n",
    "\n",
    "\n",
    "@zs.algebraic\n",
    "def chosen(infoset: zs.InfoSet):\n",
    "    infoset = cast(InfoSet, infoset)\n",
    "\n",
    "    arms = [0] * infoset.arms\n",
    "    for choice in infoset.history[::2]:\n",
    "        arm = cast(Choice, choice).arm\n",
    "        arms[arm] += 1\n",
    "    \n",
    "    return Chosen(tuple(arms))\n",
    "\n",
    "\n",
    "def actions(infoset: zs.InfoSet):\n",
    "    return infoset.actions()\n",
    "\n",
    "\n",
    "def abstract(buckets: int):\n",
    "    @zs.abstract(Learn, player * aggregate * chosen * whichround, actions)\n",
    "    class Abstraction(Learn):\n",
    "        ...\n",
    "\n",
    "    return Abstraction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the game tree is deep, even if the abstraction is significantly smaller, External Sampling MCCFR does not perform well. Indeed, each iteration is performed in $O(b^{d / 2})$ where $b$ is the branching factor and $d$ is the depth of the game tree. This is because all of the considered player's actions are explored. Outcome Sampling CFR has $O(d)$ iterations. If the abstraction used buckets together infosets at different depths, this can lead to much faster convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstraction = cast(type[Learn], abstract(4))\n",
    "\n",
    "def game(rounds: int = 10, arms: int = 2):\n",
    "    return abstraction(rounds, arms)\n",
    "\n",
    "\n",
    "impl = zs.ESLCFR(1000)\n",
    "algo = zs.Algorithm(impl, game)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Player(_=0), Scores(scores=(1, 0)), Chosen(arms=(1, 0)), Round(_=1))"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = game()\n",
    "\n",
    "g = g.apply(g.sample())\n",
    "g = g.apply(Choice(0))\n",
    "g = g.apply(g.sample())\n",
    "g = g.apply(Choice(0))\n",
    "g = g.apply(g.sample())\n",
    "g.infoset(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 69/1000 [00:40<09:05,  1.71it/s]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    for _ in tqdm(range(1000)):\n",
    "        algo.once()\n",
    "except KeyboardInterrupt:\n",
    "    pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice there are significantly fewer information sets !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1430"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(impl.strategies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:01<00:00, 959.83it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5.941"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def subg():\n",
    "    return game().apply(Init((0.2, 0.8)))\n",
    "\n",
    "evaluate(1000, game, impl.strategies)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thomspson sampling remains stronger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def thompson(means, n):\n",
    "    k = len(means)\n",
    "    priors = np.ones((k, 2))\n",
    "\n",
    "    sampled = np.empty(k)\n",
    "    payoff = 0\n",
    "\n",
    "    for _ in range(n):\n",
    "        for i in range(k):\n",
    "            sampled[i] = np.random.beta(*priors[i])\n",
    "        \n",
    "        arm = np.argmax(sampled)\n",
    "        r = np.random.choice((0, 1), p=(1 - means[arm], means[arm]))\n",
    "        priors[arm] += (r, 1 - r)\n",
    "        payoff += r\n",
    "    \n",
    "    return payoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.609"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = 0\n",
    "for _ in range(1000):\n",
    "    p += thompson((0.2, 0.8), 10)\n",
    "\n",
    "p / 1000"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clean",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7ac02b84f0b2c07ad9d596dfc0dd5b68046a23d9882df65ad98f7b44c27b887b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
