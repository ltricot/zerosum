{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning to learn\n",
    "\n",
    "We explore the bandit problem by representing it as an imperfect information game and solving it with a counterfactual regret minimization algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zerosum as zs\n",
    "\n",
    "from typing import cast\n",
    "from dataclasses import dataclass, replace\n",
    "from itertools import islice, chain\n",
    "import random"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The bandit game\n",
    "\n",
    "The bandit player chooses from a set of arms at each round, and receives a reward from the arm chosen. The reward is drawn from a distribution that depends on the arm chosen. The player's goal is to maximize their reward. The number of rounds is fixed before-hand.\n",
    "\n",
    "Our framework can currently only handle zero-sum two player games. We therefore study an alternative problem where two players play the game simultaneously. They do not share information. The payoff of each player is adjusted by the payoff of their opponent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(slots=True, frozen=True)\n",
    "class Init:\n",
    "    means: tuple[float, ...]\n",
    "\n",
    "\n",
    "@dataclass(slots=True, frozen=True)\n",
    "class Choice:\n",
    "    arm: int\n",
    "\n",
    "\n",
    "@dataclass(slots=True, frozen=True)\n",
    "class Reward:\n",
    "    reward: float\n",
    "\n",
    "\n",
    "Action = Init | Reward | Choice\n",
    "\n",
    "\n",
    "@dataclass(slots=True, frozen=True)\n",
    "class InfoSet:\n",
    "    round: int\n",
    "    arms: int\n",
    "    history: tuple[Action, ...]\n",
    "\n",
    "    def actions(self):\n",
    "        return tuple(Choice(i) for i in range(self.arms))\n",
    "\n",
    "\n",
    "@dataclass(slots=True, frozen=True)\n",
    "class Learn:\n",
    "    rounds: int\n",
    "    arms: int\n",
    "\n",
    "    round: int = 0\n",
    "    history: tuple[Action, ...] = ()\n",
    "\n",
    "    @property\n",
    "    def means(self):\n",
    "        return cast(Init, self.history[0]).means\n",
    "\n",
    "    @property\n",
    "    def terminal(self):\n",
    "        return self.round >= self.rounds\n",
    "\n",
    "    def payoff(self, player: zs.Player):\n",
    "        s0 = islice(self.history, 2, None, 4)\n",
    "        s1 = islice(self.history, 4, None, 4)\n",
    "\n",
    "        score0 = 0\n",
    "        score1 = 0\n",
    "        for a0, a1 in zip(s0, s1):\n",
    "            a0 = cast(Reward, a0)\n",
    "            a1 = cast(Reward, a1)\n",
    "            score0 += a0.reward\n",
    "            score1 += a1.reward\n",
    "\n",
    "        return score0 if player == 0 else score1\n",
    "\n",
    "    @property\n",
    "    def chance(self):\n",
    "        return len(self.history) % 2 == 0\n",
    "\n",
    "    def chances(self):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def _init(self):\n",
    "        means = tuple(random.random() for _ in range(self.arms))\n",
    "        return Init(means)\n",
    "    \n",
    "    # overriding this method in a subclass is an easy method to create\n",
    "    # a bandit game with different reward distributions\n",
    "\n",
    "    def sample(self) -> Action:\n",
    "        if len(self.history) == 0:\n",
    "            return self._init()\n",
    "\n",
    "        *_, action = self.history\n",
    "        action = cast(Choice, action)\n",
    "        if random.random() < self.means[action.arm]:\n",
    "            return Reward(1)\n",
    "        return Reward(0)\n",
    "\n",
    "    @property\n",
    "    def active(self) -> zs.Player:\n",
    "        if (len(self.history) - 1) % 4 == 0:\n",
    "            return zs.Player(0)\n",
    "        return zs.Player(1)\n",
    "\n",
    "    def infoset(self, player: zs.Player):\n",
    "        choices, rewards = self.history[1::4], self.history[2::4]\n",
    "        if player == 1:\n",
    "            choices, rewards = self.history[3::4], self.history[4::4]\n",
    "\n",
    "        history = tuple(chain.from_iterable(zip(choices, rewards)))\n",
    "        return InfoSet(self.round, self.arms, history)\n",
    "\n",
    "    def apply(self, action: Action):\n",
    "        round = self.round\n",
    "        if len(self.history) > 1 and len(self.history) % 4 == 0:\n",
    "            round += 1\n",
    "\n",
    "        return replace(self, round=round, history=self.history + (action,))\n",
    "\n",
    "\n",
    "_: zs.Game[Action, InfoSet] = Learn(0, 3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can immediately attempt to find a Nash equilibrium for this game, but we will find the number of infosets is quite large compared to the essential complexity of the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def game():\n",
    "    return Learn(10, 2)\n",
    "\n",
    "\n",
    "impl = zs.OSCFR(0.1)\n",
    "algo = zs.Algorithm(impl, game)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:01<00:00, 543.77it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "for _ in tqdm(range(1000)):\n",
    "    algo.once()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7730"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(impl.strategies)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can construct an abstraction of the game by capturing only the essential information. The player how many times each arm was pulled and their average payoff. The latter value is bucketed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fractions import Fraction as F\n",
    "\n",
    "\n",
    "@dataclass(slots=True, frozen=True)\n",
    "class Scores:\n",
    "    scores: tuple[F, ...]\n",
    "\n",
    "\n",
    "def aggregate(buckets: int):\n",
    "    @zs.algebraic\n",
    "    def aggregate(infoset: zs.InfoSet):\n",
    "        infoset = cast(InfoSet, infoset)\n",
    "        means = [0.0] * infoset.arms\n",
    "        ns = [0] * infoset.arms\n",
    "\n",
    "        for choice, action in zip(infoset.history[::2], infoset.history[1::2]):\n",
    "            arm = cast(Choice, choice).arm\n",
    "            reward = cast(Reward, action).reward\n",
    "\n",
    "            means[arm] = (reward + means[arm] * ns[arm]) / (ns[arm] + 1)\n",
    "            ns[arm] += 1\n",
    "        \n",
    "        return Scores(tuple(F(round(m * buckets), buckets) for m in means))\n",
    "    return aggregate\n",
    "\n",
    "\n",
    "@dataclass(slots=True, frozen=True)\n",
    "class Chosen:\n",
    "    arms: tuple[F, ...]\n",
    "\n",
    "\n",
    "def chosen(buckets: int):\n",
    "    @zs.algebraic\n",
    "    def chosen(infoset: zs.InfoSet):\n",
    "        infoset = cast(InfoSet, infoset)\n",
    "\n",
    "        arms = [0.0] * infoset.arms\n",
    "        for choice in infoset.history[::2]:\n",
    "            arm = cast(Choice, choice).arm\n",
    "            arms[arm] += 1 / infoset.round\n",
    "\n",
    "        return Chosen(tuple(F(round(m * buckets), buckets) for m in arms))\n",
    "    return chosen\n",
    "\n",
    "def actions(infoset: zs.InfoSet):\n",
    "    return infoset.actions()\n",
    "\n",
    "\n",
    "def abstract(buckets: int):\n",
    "    @zs.abstract(Learn, aggregate(buckets) * chosen(buckets), actions)\n",
    "    class Abstraction(Learn):\n",
    "        ...\n",
    "\n",
    "    return Abstraction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the game tree is deep, even if the abstraction is significantly smaller, External Sampling MCCFR does not perform well. Indeed, each iteration is performed in $O(b^{d / 2})$ where $b$ is the branching factor and $d$ is the depth of the game tree. This is because all of the considered player's actions are explored. Outcome Sampling CFR has $O(d)$ iterations. If the abstraction used buckets together infosets at different depths, this can lead to much faster convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstraction = cast(type[Learn], abstract(10))\n",
    "\n",
    "def game(rounds: int = 10, arms: int = 2):\n",
    "    return abstraction(rounds, arms)\n",
    "\n",
    "\n",
    "impl = zs.OSCFR(0.1)\n",
    "algo = zs.Algorithm(impl, game)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:08<00:00, 113.01it/s]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    for _ in tqdm(range(5000)):\n",
    "        algo.once()\n",
    "except KeyboardInterrupt:\n",
    "    pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice there are significantly fewer information sets ! The algorithm will run faster but still takes some time to explore all information sets adquately. MCCFR learns to play relevant situations better than irrelevant ones, as it won't explore actions with low value often."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.347\n"
     ]
    }
   ],
   "source": [
    "n = 1000\n",
    "payoff = 0\n",
    "\n",
    "for _ in range(n):\n",
    "    g = game()\n",
    "    g = g.apply(Init((0, 0.1)))\n",
    "\n",
    "    while not g.terminal:\n",
    "        if g.chance:\n",
    "            g = g.apply(g.sample())\n",
    "            continue\n",
    "\n",
    "        infoset = g.infoset(g.active)\n",
    "\n",
    "        action = infoset.actions()[0]\n",
    "        if infoset in impl.strategies:\n",
    "            s = impl.strategies[infoset]\n",
    "            action = max(s, key=s.__getitem__)\n",
    "\n",
    "        g = g.apply(action)\n",
    "\n",
    "    payoff += g.payoff(0)\n",
    "\n",
    "print(payoff / n)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clean",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7ac02b84f0b2c07ad9d596dfc0dd5b68046a23d9882df65ad98f7b44c27b887b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
